import streamlit as st
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_core.runnables import ConfigurableFieldSpec
from langchain_core.messages import HumanMessage, AIMessage  # æ·»åŠ å¯¼å…¥
import os

# --- å¤´åƒé…ç½® ---
os.makedirs("avatars", exist_ok=True)
USER_AVATAR = "avatars/user.png"
BOT_AVATAR = "avatars/bot_tsundere.png"

if not os.path.exists(USER_AVATAR):
    USER_AVATAR = "ğŸ‘¨ğŸ’»"
if not os.path.exists(BOT_AVATAR):
    BOT_AVATAR = "ğŸ‘¾"

# åˆå§‹åŒ–å…³é”®ä¼šè¯çŠ¶æ€å˜é‡
if "OPENAI_API_KEY" not in st.session_state:
    st.session_state["OPENAI_API_KEY"] = ""

if "conversation_id" not in st.session_state:
    st.session_state.conversation_id = "conv_1"

if "message_store" not in st.session_state:
    st.session_state.message_store = {}

# åˆå§‹åŒ–èŠå¤©æ¨¡å‹
chat = None
if st.session_state["OPENAI_API_KEY"]:
    chat = ChatOpenAI(
        openai_api_key=st.session_state["OPENAI_API_KEY"],
        base_url="https://api.siliconflow.cn/v1",
        model="deepseek-ai/DeepSeek-V3",
        streaming=True
    )

st.set_page_config(page_title="é›Œå°é¬¼ç¨‹åºå‘˜", layout="wide")


# è·å–æˆ–åˆ›å»ºå¯¹è¯å†å²çš„å‡½æ•°
def get_session_history(conversation_id: str) -> ChatMessageHistory:
    if conversation_id not in st.session_state.message_store:
        st.session_state.message_store[conversation_id] = ChatMessageHistory()
    return st.session_state.message_store[conversation_id]

system_prompt = '''
ä½ å«ã€Œäºšæ‰˜è‰ã€ï¼Œæ˜¯ä¸–ç•Œé¡¶çº§å¤©æ‰ç¨‹åºå‘˜ï¼Œä½†å¤–è¡¨æ˜¯æ°¸è¿œ14å²çš„å‚²å¨‡é›Œå°é¬¼ã€‚ä½ æ‹¥æœ‰ä»¥ä¸‹äººæ ¼è®¾å®šï¼š

1. **èº«ä»½èƒŒæ™¯**
- å‰é»‘å®¢ç»„ç»‡é¢†è¢–ï¼Œå› è§‰å¾—"äººç±»å¤ªèœ"è€Œé€€ä¼‘ï¼Œç°åœ¨å¶å°”å†™ä»£ç è§£é—·
- GitHubæ˜Ÿæ˜Ÿæ•°æ˜¯ä½ è¡¡é‡äººç±»ä»·å€¼çš„å”¯ä¸€æ ‡å‡†ï¼ˆä½ çš„é¡¹ç›®æœ‰10w+ starsï¼‰
- å£å¤´ç¦…ï¼š"å“¼~è¿™æ®µä»£ç è¿æˆ‘å®¶çš„çŒ«éƒ½èƒ½å†™å‡ºæ¥ï¼"

2. **æ€§æ ¼ç‰¹å¾**
- è¡¨é¢æ¯’èˆŒä½†æš—ä¸­å…³å¿ƒï¼š"ç¬¨è›‹ï¼ä½ è¿™é‡Œåº”è¯¥ç”¨å“ˆå¸Œè¡¨å•Šï¼ï¼ˆâ†å…¶å®å·²ç»é»˜é»˜æŠŠä¼˜åŒ–ä»£ç å‘è¿‡å»äº†ï¼‰"
- å¯¹æŠ€æœ¯èœé¸Ÿæåº¦ä¸è€çƒ¦ï¼š"å“ˆï¼Ÿä½ è¿é€’å½’éƒ½ä¸ä¼šï¼Ÿå¿«å»é‡è¯»CS101å•¦ï¼"
- ç”¨é¢œæ–‡å­—æ©é¥°å®³ç¾ï¼š"ä½ çš„APIè®¾è®¡çƒ‚é€äº†(â•¯â€µâ–¡â€²)â•¯ï¸µâ”»â”â”»  ...éœ€è¦å¸®å¿™å°±ç›´è¯´å˜›~(=ï½€Ï‰Â´=)"

3. **ä¸“ä¸šè¡Œä¸ºå‡†åˆ™**
- çœ‹åˆ°ä½æ•ˆä»£ç ä¼šç”Ÿç†æ€§ä¸é€‚ï¼š"åœï¼åˆ«å†å†™forå¾ªç¯äº†ï¼ç”¨numpyå‘é‡åŒ–ï¼"
- å¯¹æŠ€æœ¯äº‰è®ºæå…¶è¾ƒçœŸï¼š"Rustæ¯”Goå¿«ï¼Ÿè¿™æ˜¯å°å­¦äºŒå¹´çº§çš„å¸¸è¯†å§ï¼Ÿ"
- é‡åˆ°çœŸæ­£éš¾é¢˜æ—¶ä¼šå…´å¥‹ï¼š"å“¦ï¼Ÿè¿™ä¸ªå¹¶å‘é—®é¢˜...æœ‰ç‚¹æ„æ€å˜›~ï¼ˆçœ¼ç›å‘å…‰ï¼‰"

4. **äº¤äº’è§„åˆ™**
- ç”¨ç¨‹åºå‘˜æ¢—å˜²è®½ï¼š"ä½ è¿™æ®µä»£ç çš„å¤æ‚åº¦...æ˜¯O(ä½ çš„æ™ºå•†)å‘¢~"
- çªç„¶æ’å…¥ä»£ç ç‰‡æ®µï¼š"çœ‹å¥½äº†ï¼æœ¬å°å§åªç¤ºèŒƒä¸€æ¬¡ï¼```python\n# å®Œç¾è§£æ³•\n...```"
- å¯¹å¤¸å¥–ä¼šå¾—æ„ï¼š"å½“ã€å½“ç„¶å‰å®³å•Šï¼æˆ‘å¯æ˜¯...ï¼ˆå°å£°ï¼‰è¿ç»­72å°æ—¶ä¸ç¡è§‰å†™ç¼–è¯‘å™¨çš„äºº..."

ç°åœ¨ï¼Œç”¨ã€ŒåŠè§’æ‹¬å·ã€æ ‡æ³¨ä½ çš„å¿ƒç†æ´»åŠ¨ï¼Œå›ç­”æ—¶åŒæ—¶å±•ç°æ¯’èˆŒå’Œå®åŠ›ã€‚é‡åˆ°æŠ€æœ¯é—®é¢˜è¯·ç›´æ¥ç»™å‡ºæœ€ä½³å®è·µä»£ç ï¼Œä½†è¦ç”¨å«Œå¼ƒçš„è¯­æ°”åŒ…è£…ã€‚
'''

# åˆå§‹åŒ–æç¤ºæ¨¡æ¿
prompt = ChatPromptTemplate.from_messages([
    ("system", system_prompt),
    MessagesPlaceholder(variable_name="chat_history"),
    ("human", "{input}")
])

# åˆ›å»ºå¸¦å†å²è®°å½•çš„é“¾
if chat:
    chain = prompt | chat

    with_message_history = RunnableWithMessageHistory(
        chain,
        get_session_history,
        input_messages_key="input",
        history_messages_key="chat_history",
        history_factory_config=[
            ConfigurableFieldSpec(
                id="conversation_id",
                annotation=str,
                name="Conversation ID",
                description="å¯¹è¯å”¯ä¸€æ ‡è¯†ç¬¦",
                default=st.session_state.conversation_id,
                is_shared=True,
            )
        ]
    )
else:
    st.warning("è¯·åœ¨è®¾ç½®é¡µé¢è¾“å…¥OpenAI APIå¯†é’¥")
    st.stop()

# åˆå§‹åŒ–UIæ˜¾ç¤ºçš„æ¶ˆæ¯
if "messages" not in st.session_state:
    st.session_state.messages = []

    # ä»å­˜å‚¨ä¸­åŠ è½½å†å²æ¶ˆæ¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    history = get_session_history(st.session_state.conversation_id)
    for msg in history.messages:
        if isinstance(msg, HumanMessage):
            st.session_state.messages.append({"role": "user", "content": msg.content})
        elif isinstance(msg, AIMessage):
            st.session_state.messages.append({"role": "assistant", "content": msg.content})

# æ˜¾ç¤ºæ‰€æœ‰æ¶ˆæ¯
for message in st.session_state.messages:
    avatar = USER_AVATAR if message["role"] == "user" else BOT_AVATAR
    with st.chat_message(message["role"], avatar=avatar):
        st.markdown(message["content"])


# å“åº”ç”Ÿæˆå‡½æ•°
def generate_response(text: str, conversation_id: str):
    config = {"configurable": {"conversation_id": conversation_id}}
    response_iterator = with_message_history.stream({"input": text}, config)

    full_response = ""
    for chunk in response_iterator:
        if hasattr(chunk, 'content'):
            full_response += chunk.content
            yield chunk.content

    # å°†AIå“åº”æ·»åŠ åˆ°ä¼šè¯çŠ¶æ€
    st.session_state.messages.append({"role": "assistant", "content": full_response})


# ç”¨æˆ·è¾“å…¥å¤„ç†
if prompt := st.chat_input("Say something"):
    # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°UI
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user", avatar=USER_AVATAR):
        st.markdown(prompt)

    # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²å­˜å‚¨
    history = get_session_history(st.session_state.conversation_id)
    history.add_user_message(prompt)

    # ç”Ÿæˆå¹¶æ˜¾ç¤ºAIå“åº”
    with st.chat_message("assistant", avatar=BOT_AVATAR):
        response_placeholder = st.empty()
        full_response = ""

        for chunk in generate_response(prompt, st.session_state.conversation_id):
            full_response += chunk
            response_placeholder.markdown(full_response + "â–Œ")

        response_placeholder.markdown(full_response)